#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Module x·ª≠ l√Ω gi·∫•y t·ªù chuy√™n bi·ªát cho CDS Scanner
X·ª≠ l√Ω c√°c lo·∫°i gi·∫•y t·ªù n·ªôi b·ªô c√¥ng ty v·ªõi OCR th√¥ng minh
"""

import os
import re
import json
from datetime import datetime
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
import pytesseract
from PIL import Image
import cv2
import numpy as np

# C·∫•u h√¨nh Tesseract cho ti·∫øng Vi·ªát
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

@dataclass
class EmployeeInfo:
    """Th√¥ng tin nh√¢n vi√™n c∆° b·∫£n"""
    ho_ten: str = ""
    ma_nhan_vien: str = ""
    chuc_danh: str = ""
    bo_phan: str = ""

@dataclass
class LaborContract:
    """Th√¥ng tin h·ª£p ƒë·ªìng lao ƒë·ªông"""
    ho_ten: str = ""
    ma_nhan_vien: str = ""
    chuc_danh: str = ""
    loai_hop_dong: str = ""
    thoi_han_hop_dong: str = ""
    ngay_ky: str = ""
    ngay_hieu_luc: str = ""
    nguoi_ky: str = ""

@dataclass
class AppointmentDecision:
    """Th√¥ng tin quy·∫øt ƒë·ªãnh b·ªï nhi·ªám"""
    ho_ten: str = ""
    chuc_vu_cu: str = ""
    chuc_vu_moi: str = ""
    ngay_hieu_luc: str = ""
    nguoi_ky: str = ""
    so_quyet_dinh: str = ""

@dataclass
class TransferDecision:
    """Th√¥ng tin quy·∫øt ƒë·ªãnh ƒëi·ªÅu chuy·ªÉn"""
    ho_ten: str = ""
    bo_phan_cu: str = ""
    bo_phan_moi: str = ""
    chuc_vu: str = ""
    ngay_dieu_chuyen: str = ""
    nguoi_ky: str = ""
    so_quyet_dinh: str = ""

@dataclass
class RewardDiscipline:
    """Th√¥ng tin khen th∆∞·ªüng/k·ª∑ lu·∫≠t"""
    ho_ten: str = ""
    noi_dung_quyet_dinh: str = ""
    ngay_ban_hanh: str = ""
    hinh_thuc: str = ""  # "khen_thuong" ho·∫∑c "ky_luat"
    so_quyet_dinh: str = ""
    nguoi_ky: str = ""

class DocumentProcessor:
    """X·ª≠ l√Ω gi·∫•y t·ªù chuy√™n bi·ªát"""
    
    def __init__(self):
        self.document_types = {
            "hop_dong_lao_dong": self._extract_labor_contract,
            "quyet_dinh_bo_nhiem": self._extract_appointment_decision,
            "quyet_dinh_dieu_chuyen": self._extract_transfer_decision,
            "khen_thuong_ky_luat": self._extract_reward_discipline
        }
        
        # T·ª´ kh√≥a nh·∫≠n di·ªán lo·∫°i gi·∫•y t·ªù
        self.type_keywords = {
            "hop_dong_lao_dong": [
                "H·ª¢P ƒê·ªíNG LAO ƒê·ªòNG", "H·ª£p ƒë·ªìng lao ƒë·ªông", "HƒêLƒê",
                "B√äN A", "B√äN B", "Ng∆∞·ªùi lao ƒë·ªông", "Ng∆∞·ªùi s·ª≠ d·ª•ng lao ƒë·ªông"
            ],
            "quyet_dinh_bo_nhiem": [
                "QUY·∫æT ƒê·ªäNH B·ªî NHI·ªÜM", "Quy·∫øt ƒë·ªãnh b·ªï nhi·ªám", "B·ªï nhi·ªám",
                "Ch·ª©c v·ª•", "B·ªï nhi·ªám ch·ª©c v·ª•"
            ],
            "quyet_dinh_dieu_chuyen": [
                "QUY·∫æT ƒê·ªäNH ƒêI·ªÄU CHUY·ªÇN", "Quy·∫øt ƒë·ªãnh ƒëi·ªÅu chuy·ªÉn", "ƒêi·ªÅu chuy·ªÉn",
                "B·ªô ph·∫≠n", "Chuy·ªÉn c√¥ng t√°c"
            ],
            "khen_thuong_ky_luat": [
                "QUY·∫æT ƒê·ªäNH KHEN TH∆Ø·ªûNG", "QUY·∫æT ƒê·ªäNH K·ª∂ LU·∫¨T",
                "Khen th∆∞·ªüng", "K·ª∑ lu·∫≠t", "Th∆∞·ªüng", "Ph·∫°t"
            ]
        }
    
    def preprocess_image(self, image_path: str) -> np.ndarray:
        """Ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh ƒë·ªÉ c·∫£i thi·ªán OCR"""
        try:
            # ƒê·ªçc h√¨nh ·∫£nh
            image = cv2.imread(image_path)
            if image is None:
                raise ValueError(f"Kh√¥ng th·ªÉ ƒë·ªçc h√¨nh ·∫£nh: {image_path}")
            
            # Chuy·ªÉn sang grayscale
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # Lo·∫°i b·ªè nhi·ªÖu
            denoised = cv2.fastNlMeansDenoising(gray)
            
            # TƒÉng ƒë·ªô t∆∞∆°ng ph·∫£n
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(denoised)
            
            # Nh·ªã ph√¢n h√≥a th√≠ch ·ª©ng
            binary = cv2.adaptiveThreshold(
                enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                cv2.THRESH_BINARY, 11, 2
            )
            
            return binary
            
        except Exception as e:
            print(f"L·ªói ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh: {e}")
            return None
    
    def extract_text(self, image_path: str) -> str:
        """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ h√¨nh ·∫£nh"""
        try:
            # Ti·ªÅn x·ª≠ l√Ω h√¨nh ·∫£nh
            processed_image = self.preprocess_image(image_path)
            if processed_image is None:
                return ""
            
            # OCR v·ªõi Tesseract
            text = pytesseract.image_to_string(
                processed_image, 
                lang='vie+eng',
                config='--psm 6 --oem 3'
            )
            
            return text
            
        except Exception as e:
            print(f"L·ªói OCR: {e}")
            return ""
    
    def detect_document_type(self, text: str) -> str:
        """Nh·∫≠n di·ªán lo·∫°i gi·∫•y t·ªù d·ª±a tr√™n n·ªôi dung"""
        text_upper = text.upper()
        
        for doc_type, keywords in self.type_keywords.items():
            for keyword in keywords:
                if keyword.upper() in text_upper:
                    return doc_type
        
        return "unknown"
    
    def _extract_labor_contract(self, text: str) -> LaborContract:
        """Tr√≠ch xu·∫•t th√¥ng tin h·ª£p ƒë·ªìng lao ƒë·ªông"""
        contract = LaborContract()
        
        # T√¨m h·ªç t√™n nh√¢n vi√™n
        name_patterns = [
            r"H·ªç v√† t√™n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"Ng∆∞·ªùi lao ƒë·ªông[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"B√äN B[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in name_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                contract.ho_ten = match.group(1).strip()
                break
        
        # T√¨m m√£ nh√¢n vi√™n
        ma_patterns = [
            r"M√£ nh√¢n vi√™n[:\s]+([A-Z0-9]+)",
            r"MSNV[:\s]+([A-Z0-9]+)",
            r"M√£ s·ªë[:\s]+([A-Z0-9]+)"
        ]
        
        for pattern in ma_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                contract.ma_nhan_vien = match.group(1).strip()
                break
        
        # T√¨m ch·ª©c danh
        chuc_patterns = [
            r"Ch·ª©c danh[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"V·ªã tr√≠ c√¥ng vi·ªác[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in chuc_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                contract.chuc_danh = match.group(1).strip()
                break
        
        # T√¨m lo·∫°i h·ª£p ƒë·ªìng
        loai_patterns = [
            r"Lo·∫°i h·ª£p ƒë·ªìng[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"Th·ªùi h·∫°n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in loai_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                contract.loai_hop_dong = match.group(1).strip()
                break
        
        # T√¨m th·ªùi h·∫°n h·ª£p ƒë·ªìng
        thoi_han_patterns = [
            r"T·ª´ ng√†y[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})",
            r"ƒê·∫øn ng√†y[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})",
            r"Th·ªùi h·∫°n[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})"
        ]
        
        for pattern in thoi_han_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                contract.thoi_han_hop_dong = match.group(1).strip()
                break
        
        return contract
    
    def _extract_appointment_decision(self, text: str) -> AppointmentDecision:
        """Tr√≠ch xu·∫•t th√¥ng tin quy·∫øt ƒë·ªãnh b·ªï nhi·ªám"""
        decision = AppointmentDecision()
        
        # T√¨m h·ªç t√™n
        name_patterns = [
            r"√îng[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"B√†[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"H·ªç v√† t√™n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in name_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.ho_ten = match.group(1).strip()
                break
        
        # T√¨m ch·ª©c v·ª• m·ªõi
        chuc_moi_patterns = [
            r"B·ªï nhi·ªám[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"Ch·ª©c v·ª•[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in chuc_moi_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.chuc_vu_moi = match.group(1).strip()
                break
        
        # T√¨m ng√†y hi·ªáu l·ª±c
        ngay_patterns = [
            r"Ng√†y hi·ªáu l·ª±c[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})",
            r"C√≥ hi·ªáu l·ª±c t·ª´[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})"
        ]
        
        for pattern in ngay_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.ngay_hieu_luc = match.group(1).strip()
                break
        
        # T√¨m ng∆∞·ªùi k√Ω
        nguoi_ky_patterns = [
            r"Ng∆∞·ªùi k√Ω[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"K√Ω t√™n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in nguoi_ky_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.nguoi_ky = match.group(1).strip()
                break
        
        return decision
    
    def _extract_transfer_decision(self, text: str) -> TransferDecision:
        """Tr√≠ch xu·∫•t th√¥ng tin quy·∫øt ƒë·ªãnh ƒëi·ªÅu chuy·ªÉn"""
        decision = TransferDecision()
        
        # T√¨m h·ªç t√™n
        name_patterns = [
            r"√îng[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"B√†[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"H·ªç v√† t√™n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in name_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.ho_ten = match.group(1).strip()
                break
        
        # T√¨m b·ªô ph·∫≠n c≈©
        bo_phan_cu_patterns = [
            r"T·ª´[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"B·ªô ph·∫≠n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in bo_phan_cu_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.bo_phan_cu = match.group(1).strip()
                break
        
        # T√¨m b·ªô ph·∫≠n m·ªõi
        bo_phan_moi_patterns = [
            r"Sang[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"ƒê·∫øn[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in bo_phan_moi_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.bo_phan_moi = match.group(1).strip()
                break
        
        # T√¨m ng√†y ƒëi·ªÅu chuy·ªÉn
        ngay_patterns = [
            r"Ng√†y ƒëi·ªÅu chuy·ªÉn[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})",
            r"T·ª´ ng√†y[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})"
        ]
        
        for pattern in ngay_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.ngay_dieu_chuyen = match.group(1).strip()
                break
        
        return decision
    
    def _extract_reward_discipline(self, text: str) -> RewardDiscipline:
        """Tr√≠ch xu·∫•t th√¥ng tin khen th∆∞·ªüng/k·ª∑ lu·∫≠t"""
        decision = RewardDiscipline()
        
        # T√¨m h·ªç t√™n
        name_patterns = [
            r"√îng[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"B√†[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"H·ªç v√† t√™n[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in name_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.ho_ten = match.group(1).strip()
                break
        
        # X√°c ƒë·ªãnh lo·∫°i (khen th∆∞·ªüng hay k·ª∑ lu·∫≠t)
        if any(keyword in text.upper() for keyword in ["KHEN TH∆Ø·ªûNG", "TH∆Ø·ªûNG"]):
            decision.hinh_thuc = "khen_thuong"
        elif any(keyword in text.upper() for keyword in ["K·ª∂ LU·∫¨T", "PH·∫†T", "K·ª∂ LU·∫¨T"]):
            decision.hinh_thuc = "ky_luat"
        
        # T√¨m n·ªôi dung quy·∫øt ƒë·ªãnh
        noi_dung_patterns = [
            r"N·ªôi dung[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)",
            r"L√Ω do[:\s]+([A-Z√Ä√Å·∫†·∫¢√É√Ç·∫¶·∫§·∫¨·∫®·∫™ƒÇ·∫∞·∫Æ·∫∂·∫≤·∫¥√à√â·∫∏·∫∫·∫º√ä·ªÄ·∫æ·ªÜ·ªÇ·ªÑ√å√ç·ªä·ªàƒ®√í√ì·ªå·ªé√ï√î·ªí·ªê·ªò·ªî·ªñ∆†·ªú·ªö·ª¢·ªû·ª†√ô√ö·ª§·ª¶≈®∆Ø·ª™·ª®·ª∞·ª¨·ªÆ·ª≤√ù·ª¥·ª∂·ª∏ƒê\s]+)"
        ]
        
        for pattern in noi_dung_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.noi_dung_quyet_dinh = match.group(1).strip()
                break
        
        # T√¨m ng√†y ban h√†nh
        ngay_patterns = [
            r"Ng√†y ban h√†nh[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})",
            r"Ng√†y[:\s]+(\d{1,2}[/-]\d{1,2}[/-]\d{4})"
        ]
        
        for pattern in ngay_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                decision.ngay_ban_hanh = match.group(1).strip()
                break
        
        return decision
    
    def process_document(self, image_path: str) -> Dict[str, Any]:
        """X·ª≠ l√Ω gi·∫•y t·ªù v√† tr·∫£ v·ªÅ k·∫øt qu·∫£"""
        try:
            # Tr√≠ch xu·∫•t vƒÉn b·∫£n
            text = self.extract_text(image_path)
            if not text:
                return {"error": "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ h√¨nh ·∫£nh"}
            
            # Nh·∫≠n di·ªán lo·∫°i gi·∫•y t·ªù
            doc_type = self.detect_document_type(text)
            if doc_type == "unknown":
                return {
                    "error": "Kh√¥ng th·ªÉ nh·∫≠n di·ªán lo·∫°i gi·∫•y t·ªù",
                    "extracted_text": text[:500] + "..." if len(text) > 500 else text
                }
            
            # X·ª≠ l√Ω theo lo·∫°i gi·∫•y t·ªù
            if doc_type in self.document_types:
                result = self.document_types[doc_type](text)
                return {
                    "document_type": doc_type,
                    "extracted_text": text,
                    "processed_data": asdict(result),
                    "confidence": "high"
                }
            
            return {"error": f"Lo·∫°i gi·∫•y t·ªù kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£: {doc_type}"}
            
        except Exception as e:
            return {"error": f"L·ªói x·ª≠ l√Ω gi·∫•y t·ªù: {str(e)}"}
    
    def save_result(self, result: Dict[str, Any], output_path: str):
        """L∆∞u k·∫øt qu·∫£ x·ª≠ l√Ω v√†o file JSON"""
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o: {output_path}")
        except Exception as e:
            print(f"L·ªói l∆∞u file: {e}")

# H√†m ti·ªán √≠ch ƒë·ªÉ test
def test_document_processor():
    """Test module x·ª≠ l√Ω gi·∫•y t·ªù"""
    processor = DocumentProcessor()
    
    print("üîç CDS Document Processor - Test Mode")
    print("=" * 50)
    
    # Test c√°c pattern nh·∫≠n di·ªán
    print("üìã C√°c lo·∫°i gi·∫•y t·ªù ƒë∆∞·ª£c h·ªó tr·ª£:")
    for doc_type, keywords in processor.type_keywords.items():
        print(f"  ‚Ä¢ {doc_type.replace('_', ' ').title()}")
        for keyword in keywords[:3]:  # Ch·ªâ hi·ªÉn th·ªã 3 t·ª´ kh√≥a ƒë·∫ßu
            print(f"    - {keyword}")
    
    print("\n‚úÖ Module ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng!")
    print("\nüìù C√°ch s·ª≠ d·ª•ng:")
    print("  processor = DocumentProcessor()")
    print("  result = processor.process_document('path/to/image.jpg')")
    print("  processor.save_result(result, 'output.json')")

if __name__ == "__main__":
    test_document_processor()
